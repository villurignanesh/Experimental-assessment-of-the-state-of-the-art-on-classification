# Experimental-assessment-of-the-state-of-the-art-on-classification
Real world data is not only vast but heterogeneous. Data incorporates several features that require an independent way of processing. The challenge with forecasting is the model selection. Selecting a model based on historical records might not always be accurate. The main challenge is to grasp which boundaries, information, and metadata should be considered to show up at the last decision. Significantly seriously testing, we really want to comprehend if a boundary with a high worth, say a higher measurement score, truly implies the model is superior to one with a lower score, or on the other hand on the off chance that it's just brought about by bias or misled measurement plan. This discrepancy leads us to our project where we assess the state of art on classification
